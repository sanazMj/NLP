{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WvOJsim8OYY",
        "outputId": "8cd76c23-5ecd-4f7e-fe73-72ad5730c581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AcUAiCrY9Bgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f2ba243-e734-45b3-b95a-b6a260143e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EW3ivVeH9efj"
      },
      "outputs": [],
      "source": [
        "Main_dir = '/content/drive/MyDrive/NLP/GAN_for_text_generation/'\n",
        "Data_dir = '/content/drive/MyDrive/NLP/GAN_for_text_generation/Software_engineering_Datasets/SentimentAnalysis/'\n",
        "Data_dir_replication = '/replication/dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QsESjwJG9gGb"
      },
      "outputs": [],
      "source": [
        "Data_files_names = ['oracle.xlsx', 'BenchmarkUddinSO-ConsoliatedAspectSentiment.xls', 'github_gold.csv','AppReviews.csv', 'JIRA.csv', 'StackOverflow.csv']\n",
        "Data_files = {'CR': Data_dir + Data_files_names[0],\n",
        "              'API': Data_dir + Data_files_names[1],\n",
        "              'SO': Data_dir + Data_dir_replication  + Data_files_names[5],\n",
        "              'JIRA': Data_dir + Data_dir_replication  + Data_files_names[4],\n",
        "              'AppReviews':Data_dir + Data_dir_replication  + Data_files_names[3]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1kNNJgQY9hHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530164f4-2297-4578-c902-4f11c1592db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/GAN_for_text_generation\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(Main_dir)\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QuOnQ9Z_9Ch8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "266ce695352a4aee93e0e6af95a89115",
            "4cb318eb4c1846d4b37351747d35a33c",
            "50a1ff0e1779404f86b9f3ffc13becbd",
            "b1a37b42ea89423197c599c395cfedc5",
            "3b5a620db81f403d8a17d8b3935900f2",
            "67f5b4688ac0464bb73d287d25c2ccb9",
            "84f7bcdaac2c49969f059e0c4de5ce2f",
            "38dcfce2780148b1b0a92c7cf3876f16",
            "94d6db0a65884e79a554f432560f9f78",
            "aa8e838143d0469cb6bd11e98eda09ba",
            "c6f88a9e42c94cf1b8cb23cc9cb82652"
          ]
        },
        "outputId": "a1087e7b-3d37-405d-beee-39db737cc43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "266ce695352a4aee93e0e6af95a89115"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import os.path\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbXpGFlN--Wi"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfu7B8r4-4o2",
        "outputId": "8ff071d2-d569-409c-f90e-07b7c77010c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data = pd.read_csv(Data_files['SO'])\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "siAo_4mX-9tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a21451-d5e5-44f8-892d-3873c42086ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    1191\n",
              "-1     178\n",
              " 1     131\n",
              "Name: oracle, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data['oracle'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aj1Ri2IONwiS"
      },
      "outputs": [],
      "source": [
        "data['oracle_new'] = data['oracle'] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gvxoliez_A9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3cc705a1-c57a-4dd4-f22d-f83eaa714831"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id                                               text  oracle  oracle_new\n",
              "0    6                     But sadly this is not working.      -1           0\n",
              "1   78  So, everything builds fine, but when we try to...      -1           0\n",
              "2   90  That is what is causing your null pointer exce...      -1           0\n",
              "3  139  All attempts I've made were, in a shortcut, un...      -1           0\n",
              "4  162                                         Don't use.      -1           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f47e0946-88ab-47ab-b6cf-f3116add7b72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>oracle</th>\n",
              "      <th>oracle_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>But sadly this is not working.</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>78</td>\n",
              "      <td>So, everything builds fine, but when we try to...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90</td>\n",
              "      <td>That is what is causing your null pointer exce...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>139</td>\n",
              "      <td>All attempts I've made were, in a shortcut, un...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>162</td>\n",
              "      <td>Don't use.</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f47e0946-88ab-47ab-b6cf-f3116add7b72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f47e0946-88ab-47ab-b6cf-f3116add7b72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f47e0946-88ab-47ab-b6cf-f3116add7b72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XtkaEyy_Nu-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0d002f-c942-4282-ca3e-b04a24217785"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1191\n",
              "0     178\n",
              "2     131\n",
              "Name: oracle_new, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data['oracle_new'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4wWaTnlMHjiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0daac9de-78f2-4ddf-b42d-6f591765ae87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1125,) (375,) (1125,) (375,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['oracle_new'],\n",
        "                                                    stratify= data['oracle_new'], \n",
        "                                                    test_size=0.25)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3CvRTHLJAgSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9217ee76-8c26-4c4f-d57a-ed77d3be17d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), array([134, 893,  98]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "np.unique(y_train, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IXAd1FpKH2Pk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28225f75-abdb-48ef-a2ce-291117c7a3ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), array([ 44, 298,  33]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "np.unique(y_test, return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set the hyperparameters"
      ],
      "metadata": {
        "id": "-C-7dCp70WgN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "STFDBeFP_F_s"
      },
      "outputs": [],
      "source": [
        "train_maxlen = 140\n",
        "dev_maxlen = 140\n",
        "batch_size = 20 #16\n",
        "epochs = 10 # 10\n",
        "bert_model = 'bert-base-uncased'\n",
        "learning_rate = 3e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "M3X43lpk_chS"
      },
      "outputs": [],
      "source": [
        "class Tokenize_dataset:\n",
        "  \"\"\"\n",
        "  This class tokenizes the dataset using bert tokenizer\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, text, targets, tokenizer, max_len):\n",
        "    self.text = text\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    text = str(self.text[item])\n",
        "    targets = self.targets[item]\n",
        "    \"\"\"\n",
        "    Using encode_plus instead of encode as it helps to provide additional information that we need\n",
        "    \"\"\"\n",
        "    inputs = self.tokenizer.encode_plus(\n",
        "        str(text),\n",
        "        add_special_tokens = True,\n",
        "        max_length = self.max_len,\n",
        "        pad_to_max_length = True\n",
        "    )\n",
        "\n",
        "    ids = inputs[\"input_ids\"]\n",
        "    mask = inputs[\"attention_mask\"]\n",
        "    token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "    return {\n",
        "        \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "        \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "        \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "        \"targets\": torch.tensor(targets, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8tK19Prc_d1K"
      },
      "outputs": [],
      "source": [
        "def loss_function(outputs, targets):\n",
        "\t\"\"\"\n",
        "\tThis function defines the loss function we use in the model which since is multiclass is crossentropy\n",
        "\t\"\"\"\n",
        "\treturn nn.CrossEntropyLoss()(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "pQMCmmeQ_e3F"
      },
      "outputs": [],
      "source": [
        "def train_function(data_loader, model, optimizer, device):\n",
        "  \"\"\"\n",
        "  Function defines the training that we will happen over the entire dataset\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "\n",
        "  running_loss = 0.0\n",
        "  \"\"\"\n",
        "  looping over the entire training dataset\n",
        "  \"\"\"\n",
        "  for i, data in enumerate(data_loader):\n",
        "    mask = data[\"mask\"].to(device, dtype=torch.long)\n",
        "    ids = data[\"ids\"].to(device, dtype=torch.long)\n",
        "    token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
        "    target = data[\"targets\"].to(device, dtype=torch.long)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "    # print(output, target)\n",
        "    loss = loss_function(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \"\"\"\n",
        "    calculating loss and running loss\n",
        "    \"\"\"\n",
        "    running_loss += loss.item()\n",
        "    if i % 10 == 0 and i!=0:\n",
        "      temp = f'Batch index = {i}\\tRunning Loss = {running_loss/10}'\n",
        "      print(temp)\n",
        "      running_loss = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6NSEYFpE_gSr"
      },
      "outputs": [],
      "source": [
        "def eval_function(data_loader, model, device):\n",
        "  \"\"\"\n",
        "  This function defines the loop over the dev set.\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  correct_labels = 0\n",
        "  tot = 0\n",
        "  \"\"\"\n",
        "  no_grad as this is evaluation set and we dont want the model to update weights\n",
        "  \"\"\"\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(data_loader):\n",
        "      mask = data[\"mask\"].to(device, dtype=torch.long)\n",
        "      ids = data[\"ids\"].to(device, dtype=torch.long)\n",
        "      token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
        "      targets = data[\"targets\"].to(device, dtype=torch.long)\n",
        "      outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "\n",
        "      max_probs, predicted = torch.max(outputs, 1)\n",
        "      tot = tot + targets.size(0)\n",
        "      correct_labels = correct_labels + torch.sum(predicted==targets)\n",
        "\n",
        "      print(f\"Batch Index: {i}\\tPredicted: {predicted}\\tTargets: {targets}\")\n",
        "    \"\"\"\n",
        "    basic metrics for accuracy calculation\n",
        "    \"\"\"\n",
        "    accuracy = correct_labels / tot * 100\n",
        "    print(accuracy)\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "7NzKjKPZ_hhC"
      },
      "outputs": [],
      "source": [
        "class CompleteModel(nn.Module):\n",
        "  \"\"\"\n",
        "  The model architecture is defined here which is a fully connected layer + normalization on top of a BERT model\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, bert):\n",
        "    super(CompleteModel, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(bert)\n",
        "    self.drop = nn.Dropout(p=0.25)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, 3) # Number of output classes = 3, positive, negative and N(none)\n",
        "\n",
        "  def forward(self, ids, mask, token_type_ids):\n",
        "    _, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "zgFtegcM_jLu"
      },
      "outputs": [],
      "source": [
        "def run(train_text, train_target):\n",
        "  # training_set_path = \"/content/drive/MyDrive/NLP_disaster/train.csv\"\n",
        "  #   #validation_set_path = '/content/drive/MyDrive/dataset/dev/' + str(location) + '_' + str(aspect) + '.csv'\n",
        "  # df_train = pd.read_csv(training_set_path)\n",
        "    #df_valid = pd.read_csv(validation_set_path)\n",
        "      \n",
        "  # df_train['target'] = df_train['target']\n",
        "   # df_valid['target'] = df_valid['target'].map(sentiment_mapping)\n",
        "  # df_train = df_train.reset_index(drop=True)\n",
        "   # df_valid = df_valid.reset_index(drop=True)\n",
        "  tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "  train_dataset = Tokenize_dataset(\n",
        "        text = train_text.values,\n",
        "        targets = train_target.values,\n",
        "        tokenizer = tokenizer,\n",
        "        max_len = train_maxlen\n",
        "  )\n",
        "  class_counts = []\n",
        "  unique_labels = np.unique(y_train.values)\n",
        "  for i in unique_labels:\n",
        "    class_counts.append(train_text.values[train_target.values==i].shape[0])\n",
        "  print(f\"Class Counts: {class_counts}\")\n",
        "      \n",
        "  num_samples = sum(class_counts)\n",
        "  print(num_samples)\n",
        "  labels = train_target.values\n",
        "  class_weights = {}\n",
        "  for i in range(len(class_counts)):\n",
        "      if class_counts[i] != 0:\n",
        "          class_weights[unique_labels[i]] = (num_samples/class_counts[i])\n",
        "      else:\n",
        "          class_weights[unique_labels[i]] = 0\n",
        "  print('Class weights', class_weights)\n",
        "  weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
        "  sampler = torch.utils.data.sampler.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
        "  train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size = batch_size,\n",
        "        shuffle = False,\n",
        "        sampler = sampler\n",
        "    )\n",
        "  #valid_dataset = Tokenize_dataset(\n",
        "    #    text = df_valid['text'].values,\n",
        "     #   targets = df_valid['sentiment'].values,\n",
        "    #   tokenizer = tokenizer,\n",
        "     #   max_len = dev_maxlen\n",
        "   # )\n",
        "   # valid_data_loader = torch.utils.data.DataLoader(\n",
        "    #    valid_dataset,\n",
        "     #   batch_size = batch_size,\n",
        "   #     shuffle = False\n",
        "#    )\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Device: {device}\")\n",
        "  model = CompleteModel(bert_model).to(device)\n",
        "  optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "  scheduler = lr_scheduler.StepLR(\n",
        "        optimizer,\n",
        "        step_size = 1,\n",
        "        gamma = 0.8\n",
        "    )\n",
        "  for epoch in range(epochs):\n",
        "    train_function(data_loader=train_data_loader, model=model, optimizer=optimizer, device=device)\n",
        "        #accuracy = eval_function(data_loader=valid_data_loader, model=model, device=device, location=location, aspect=aspect)\n",
        "    print(\"\\nEpoch = \"+ str(epoch))\n",
        "    print(\"\\nLearning Rate = \" + str(scheduler.get_lr()[0])+\"\\n\")\n",
        "    scheduler.step()\n",
        "    torch.save(model, Main_dir + '/Models/'+ '/'+ str(epoch) + '.bin')\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St-uJzZpAdGL"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PFEgWGX1AZZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e47b2e-2960-4309-854e-de4f1a722b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Counts: [134, 893, 98]\n",
            "1125\n",
            "Class weights {0: 8.395522388059701, 1: 1.2597984322508398, 2: 11.479591836734693}\n",
            "Device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch index = 10\tRunning Loss = 1.1949561715126038\n",
            "Batch index = 20\tRunning Loss = 1.0266030788421632\n",
            "Batch index = 30\tRunning Loss = 0.9307244122028351\n",
            "Batch index = 40\tRunning Loss = 0.7963219523429871\n",
            "Batch index = 50\tRunning Loss = 0.6513383984565735\n",
            "\n",
            "Epoch = 0\n",
            "\n",
            "Learning Rate = 3e-05\n",
            "\n",
            "Batch index = 10\tRunning Loss = 0.4502914726734161\n",
            "Batch index = 20\tRunning Loss = 0.29302823543548584\n",
            "Batch index = 30\tRunning Loss = 0.26442293301224706\n",
            "Batch index = 40\tRunning Loss = 0.2696003369987011\n",
            "Batch index = 50\tRunning Loss = 0.15263351425528526\n",
            "\n",
            "Epoch = 1\n",
            "\n",
            "Learning Rate = 1.9200000000000003e-05\n",
            "\n",
            "Batch index = 10\tRunning Loss = 0.20274244770407676\n",
            "Batch index = 20\tRunning Loss = 0.143890193849802\n",
            "Batch index = 30\tRunning Loss = 0.10856764428317547\n",
            "Batch index = 40\tRunning Loss = 0.0875805677846074\n",
            "Batch index = 50\tRunning Loss = 0.08162803947925568\n",
            "\n",
            "Epoch = 2\n",
            "\n",
            "Learning Rate = 1.5360000000000002e-05\n",
            "\n",
            "Batch index = 10\tRunning Loss = 0.08434091433882714\n",
            "Batch index = 20\tRunning Loss = 0.07323548346757888\n",
            "Batch index = 30\tRunning Loss = 0.05062484238296747\n",
            "Batch index = 40\tRunning Loss = 0.08026178302243352\n",
            "Batch index = 50\tRunning Loss = 0.07610316667705774\n",
            "\n",
            "Epoch = 3\n",
            "\n",
            "Learning Rate = 1.2288000000000002e-05\n",
            "\n",
            "Batch index = 10\tRunning Loss = 0.032666045054793355\n",
            "Batch index = 20\tRunning Loss = 0.03607986718416214\n",
            "Batch index = 30\tRunning Loss = 0.02196133527904749\n",
            "Batch index = 40\tRunning Loss = 0.013877105619758367\n",
            "Batch index = 50\tRunning Loss = 0.03389369454234838\n",
            "\n",
            "Epoch = 4\n",
            "\n",
            "Learning Rate = 9.830400000000002e-06\n",
            "\n",
            "Batch index = 10\tRunning Loss = 0.01849482748657465\n",
            "Batch index = 20\tRunning Loss = 0.037517505092546345\n",
            "Batch index = 30\tRunning Loss = 0.023809120850637557\n",
            "Batch index = 40\tRunning Loss = 0.011407594941556454\n",
            "Batch index = 50\tRunning Loss = 0.04839264671318233\n",
            "\n",
            "Epoch = 5\n",
            "\n",
            "Learning Rate = 7.864320000000002e-06\n",
            "\n",
            "Batch index = 10\tRunning Loss = 0.02902746982872486\n",
            "Batch index = 20\tRunning Loss = 0.06368337469175459\n",
            "Batch index = 30\tRunning Loss = 0.022156732296571134\n",
            "Batch index = 40\tRunning Loss = 0.012333077006042003\n",
            "Batch index = 50\tRunning Loss = 0.011556412372738124\n",
            "\n",
            "Epoch = 6\n",
            "\n",
            "Learning Rate = 6.291456000000002e-06\n",
            "\n",
            "Batch index = 10\tRunning Loss = 0.038070856546983126\n",
            "Batch index = 20\tRunning Loss = 0.06274397354573011\n",
            "Batch index = 30\tRunning Loss = 0.010130915604531766\n",
            "Batch index = 40\tRunning Loss = 0.017966217268258332\n",
            "Batch index = 50\tRunning Loss = 0.014981362130492925\n",
            "\n",
            "Epoch = 7\n",
            "\n",
            "Learning Rate = 5.033164800000002e-06\n",
            "\n",
            "Batch index = 10\tRunning Loss = 0.05837224740535021\n",
            "Batch index = 20\tRunning Loss = 0.024700928013771772\n",
            "Batch index = 30\tRunning Loss = 0.014756469987332821\n",
            "Batch index = 40\tRunning Loss = 0.008558577299118042\n",
            "Batch index = 50\tRunning Loss = 0.00586369251832366\n",
            "\n",
            "Epoch = 8\n",
            "\n",
            "Learning Rate = 4.026531840000002e-06\n",
            "\n",
            "Batch index = 10\tRunning Loss = 0.008453864743933082\n",
            "Batch index = 20\tRunning Loss = 0.005261062271893024\n",
            "Batch index = 30\tRunning Loss = 0.00659299767576158\n",
            "Batch index = 40\tRunning Loss = 0.00895896798465401\n",
            "Batch index = 50\tRunning Loss = 0.007053259434178472\n",
            "\n",
            "Epoch = 9\n",
            "\n",
            "Learning Rate = 3.221225472000002e-06\n",
            "\n"
          ]
        }
      ],
      "source": [
        "run(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7pqDApKAW6z"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "VAp0a41D0owc"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "J0Gfqv6-_lyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa693a76-2cd9-4914-a598-fb15abbd3d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Class Negative       0.62      0.52      0.57        44\n",
            " Class Neutral       0.93      0.72      0.81       298\n",
            "Class Positive       0.22      0.73      0.34        33\n",
            "\n",
            "      accuracy                           0.70       375\n",
            "     macro avg       0.59      0.66      0.57       375\n",
            "  weighted avg       0.83      0.70      0.74       375\n",
            "\n",
            "epoch 1\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Class Negative       0.63      0.66      0.64        44\n",
            " Class Neutral       0.93      0.89      0.91       298\n",
            "Class Positive       0.50      0.67      0.57        33\n",
            "\n",
            "      accuracy                           0.84       375\n",
            "     macro avg       0.69      0.74      0.71       375\n",
            "  weighted avg       0.86      0.84      0.85       375\n",
            "\n",
            "epoch 2\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Class Negative       0.65      0.70      0.67        44\n",
            " Class Neutral       0.93      0.90      0.91       298\n",
            "Class Positive       0.56      0.67      0.61        33\n",
            "\n",
            "      accuracy                           0.86       375\n",
            "     macro avg       0.71      0.76      0.73       375\n",
            "  weighted avg       0.86      0.86      0.86       375\n",
            "\n",
            "epoch 3\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Class Negative       0.74      0.70      0.72        44\n",
            " Class Neutral       0.93      0.92      0.92       298\n",
            "Class Positive       0.55      0.64      0.59        33\n",
            "\n",
            "      accuracy                           0.87       375\n",
            "     macro avg       0.74      0.75      0.75       375\n",
            "  weighted avg       0.87      0.87      0.87       375\n",
            "\n",
            "epoch 4\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Class Negative       0.71      0.66      0.68        44\n",
            " Class Neutral       0.91      0.94      0.92       298\n",
            "Class Positive       0.69      0.55      0.61        33\n",
            "\n",
            "      accuracy                           0.87       375\n",
            "     macro avg       0.77      0.71      0.74       375\n",
            "  weighted avg       0.87      0.87      0.87       375\n",
            "\n",
            "epoch 5\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Class Negative       0.69      0.66      0.67        44\n",
            " Class Neutral       0.91      0.94      0.92       298\n",
            "Class Positive       0.68      0.52      0.59        33\n",
            "\n",
            "      accuracy                           0.87       375\n",
            "     macro avg       0.76      0.70      0.73       375\n",
            "  weighted avg       0.86      0.87      0.86       375\n",
            "\n",
            "epoch 6\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Class Negative       0.73      0.61      0.67        44\n",
            " Class Neutral       0.91      0.93      0.92       298\n",
            "Class Positive       0.61      0.61      0.61        33\n",
            "\n",
            "      accuracy                           0.87       375\n",
            "     macro avg       0.75      0.72      0.73       375\n",
            "  weighted avg       0.86      0.87      0.86       375\n",
            "\n",
            "epoch 7\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Class Negative       0.70      0.64      0.67        44\n",
            " Class Neutral       0.91      0.95      0.93       298\n",
            "Class Positive       0.75      0.55      0.63        33\n",
            "\n",
            "      accuracy                           0.87       375\n",
            "     macro avg       0.79      0.71      0.74       375\n",
            "  weighted avg       0.87      0.87      0.87       375\n",
            "\n",
            "epoch 8\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Class Negative       0.71      0.68      0.70        44\n",
            " Class Neutral       0.92      0.93      0.93       298\n",
            "Class Positive       0.61      0.61      0.61        33\n",
            "\n",
            "      accuracy                           0.87       375\n",
            "     macro avg       0.75      0.74      0.74       375\n",
            "  weighted avg       0.87      0.87      0.87       375\n",
            "\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 140\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/NLP_disaster/test.csv\")\n",
        "for epoch in range(epochs-1):\n",
        "\n",
        "  result = []\n",
        "  idees = []\n",
        "  model = torch.load(Main_dir + '/Models/'+ '/'+ str(epoch) + '.bin')\n",
        "  for i in range(len(X_test)):\n",
        "    id_test = X_test.keys()[i]\n",
        "    text = X_test.values[i]\n",
        "\n",
        "\n",
        "    inputs = tokenizer.encode_plus(\n",
        "            str(text),\n",
        "            add_special_tokens = True,\n",
        "            max_length = MAX_LEN,\n",
        "            pad_to_max_length = True,\n",
        "        )\n",
        "    ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).unsqueeze(0)\n",
        "    mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).unsqueeze(0)\n",
        "    token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    ids = ids.to(device, dtype=torch.long)\n",
        "    mask = mask.to(device, dtype=torch.long)\n",
        "    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "\n",
        "  #model = models_set[f\"{location}{aspect}\"]\n",
        "    outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "    prob_max, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    predicted = predicted.detach().cpu().numpy()\n",
        "\n",
        "          # Add the predicted to the json only if it is not N(none)\n",
        "          # Reverse mapping from numbers to sentiments\n",
        "    idees.append(id_test)\n",
        "    result.append(predicted[0])\n",
        "    # 1 positive, 0 neutral, -1 negative \n",
        "  target_names = ['Class Negative', 'Class Neutral', 'Class Positive']\n",
        "  print('epoch', epoch)\n",
        "  print(classification_report(y_test, result,target_names = target_names))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "koL3eAGLzdCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "266ce695352a4aee93e0e6af95a89115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cb318eb4c1846d4b37351747d35a33c",
              "IPY_MODEL_50a1ff0e1779404f86b9f3ffc13becbd",
              "IPY_MODEL_b1a37b42ea89423197c599c395cfedc5"
            ],
            "layout": "IPY_MODEL_3b5a620db81f403d8a17d8b3935900f2"
          }
        },
        "4cb318eb4c1846d4b37351747d35a33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67f5b4688ac0464bb73d287d25c2ccb9",
            "placeholder": "​",
            "style": "IPY_MODEL_84f7bcdaac2c49969f059e0c4de5ce2f",
            "value": ""
          }
        },
        "50a1ff0e1779404f86b9f3ffc13becbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38dcfce2780148b1b0a92c7cf3876f16",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94d6db0a65884e79a554f432560f9f78",
            "value": 0
          }
        },
        "b1a37b42ea89423197c599c395cfedc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8e838143d0469cb6bd11e98eda09ba",
            "placeholder": "​",
            "style": "IPY_MODEL_c6f88a9e42c94cf1b8cb23cc9cb82652",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "3b5a620db81f403d8a17d8b3935900f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f5b4688ac0464bb73d287d25c2ccb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f7bcdaac2c49969f059e0c4de5ce2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38dcfce2780148b1b0a92c7cf3876f16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "94d6db0a65884e79a554f432560f9f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa8e838143d0469cb6bd11e98eda09ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f88a9e42c94cf1b8cb23cc9cb82652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}